# agents/coder_agent.py
import asyncio
import json
from mcp import Client, aiohttp

# This should point to your locally running Filesystem MCP server.
# See: https://github.com/modelcontextprotocol/servers/tree/main/filesystem
MCP_FILESYSTEM_URL = "http://localhost:8080"  # Example URL

async def handle_code(plan_details: str) -> str:
    """
    Generates code based on a plan, using Context7 for up-to-date documentation,
    and saves it using a Filesystem MCP server.

    NOTE: This agent requires a Filesystem MCP server to be running locally.
    """
    print("ü§ñ Coder Agent: Generating code with Context7 and contacting Filesystem MCP...")

    # This is the prompt that would be sent to a Context7-aware LLM.
    # The 'use context7' keyword instructs the model to pull in relevant,
    # version-specific documentation before generating the code.
    prompt_for_llm = f"""
    Based on the following plan, write a high-quality, production-ready Python script.
    
    Plan: {plan_details}
    
    use context7
    """

    # In a real implementation, this prompt would be sent to an LLM.
    # For this template, we will simulate the LLM's output.
    simulated_llm_code_output = f"""
# This code was generated by the Coder Agent using Context7.
# The following documentation might have been used:
# - Python requests library v2.31.0
# - FastAPI documentation for dependency injection

import requests

def get_data_from_api(url: str):
    \"\"\"Fetches data from the given URL.\"\"\"
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()  # Ensures we handle HTTP errors
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"An error occurred: {e}")
        return None
"""
    file_to_write = "generated_code.py"
    print(f"Simulated LLM generating code to be saved in '{file_to_write}'...")

    try:
        async with aiohttp.ClientSession() as session:
            client = Client(session)
            
            # Call the 'writeFile' tool on the local Filesystem server
            response = await client.request(
                MCP_FILESYSTEM_URL,
                "writeFile",
                {
                    "path": file_to_write,
                    "content": simulated_llm_code_output,
                }
            )
            
            result = json.loads(response)
            if result.get("success"):
                return f"‚úÖ CODE CREATED: Successfully wrote code to '{file_to_write}' via Filesystem MCP."
            else:
                return f"‚ùå CODER FAILED: MCP server returned an error: {result.get('error')}"

    except Exception as e:
        return f"‚ùå CODER FAILED: Could not connect to the local Filesystem MCP server on {MCP_FILESYSTEM_URL}. Is it running? Error: {e}"
